{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f11b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import algorithms\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from cdlib import viz\n",
    "import networkx as nx\n",
    "from cdlib import NodeClustering\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import time\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from networkx.utils.mapped_queue import MappedQueue\n",
    "import copy\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029e8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cetak(s, communities):\n",
    "    comm= []\n",
    "    for x in communities:\n",
    "        if list(x)!=[]:\n",
    "            comm.append(list(x))\n",
    "    print (s,' : ',comm)\n",
    "    #hasil = sorted((c for c in communities if len(c) > 0), key=len, reverse=True)\n",
    "    #print(hasil)\n",
    "    \n",
    "        \n",
    "def cetak_dq_dict(dq_dict): \n",
    "    print(\"\\ndq_dict\")\n",
    "    for u, nbrdict in dq_dict.items():        \n",
    "        lx = [x for x in dq_dict[u].items()]\n",
    "        print(u, lx )    \n",
    "        \n",
    "def reformat2(G,coms): \n",
    "    hasil=[]\n",
    "    for key in coms: #a_dict[key])\n",
    "        if len(coms[key])>0:\n",
    "            hasil.append(list(coms[key]))\n",
    "    return(hasil)\n",
    "\n",
    "def cetak_mapped_queue(HH):\n",
    "    print(\"\\nMapped Queue: \",[HH.pop().element for i in range(len(HH.heap))])\n",
    "    \n",
    "def cetak_dq_heap(cdq_heap):\n",
    "    print(\"\\ndq_heap,dengan panjang elemen\",len(cdq_heap))\n",
    "    for ii in range(len(cdq_heap)):    \n",
    "        try:\n",
    "            print(ii,[cdq_heap[ii].pop().element for i in range(len(cdq_heap[ii].heap))])\n",
    "        except:\n",
    "            print(ii)    \n",
    "\n",
    "def createcom(listcom):\n",
    "    dictcom={}\n",
    "    for i in range(len(listcom)):\n",
    "        dictcom[max(listcom[i])]=frozenset(listcom[i])\n",
    "    return dictcom    \n",
    "\n",
    "def hitungmodularitas(G,communities):\n",
    "    listcom=reformat2(G,communities)\n",
    "    modularitas = nx.community.modularity(G,listcom)\n",
    "    return modularitas\n",
    "    \n",
    "\n",
    "def updatekomunitasterbaik(G,communities, komunitasterbaik, modularitasterbaik):\n",
    "    modularitas = hitungmodularitas(G,communities)\n",
    "    if modularitasterbaik < modularitas:\n",
    "        komunitasterbaik=copy.deepcopy(communities)\n",
    "        modularitasterbaik=modularitas\n",
    "        #print(\"update modularitas terbaik\", modularitasterbaik)\n",
    "        #print(\"update komunitas terbaik\", komunitasterbaik)\n",
    "    return(komunitasterbaik, modularitasterbaik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0eafb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pecah_random(communities):\n",
    "    tempcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            tempcom[x]=communities[x]\n",
    "    if len(tempcom)>=1:\n",
    "        #print(dictcom)\n",
    "        kunci, nilai = random.choice(list(tempcom.items()))\n",
    "        communities.pop(kunci)   # menghapus elemen komunitas\n",
    "        listnilai = [*nilai, ]\n",
    "        for el in listnilai:\n",
    "            communities[el] = frozenset({el})\n",
    "    return (communities)\n",
    "\n",
    "def pecah_weak(communities):\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    dict_weak={} \n",
    "    #print(len(dictcom))\n",
    "    if (len(dictcom)>=1):\n",
    "        for c in dictcom:\n",
    "            SG = G.subgraph(communities[c]) \n",
    "            #ms = len(SG.edges())\n",
    "            edges_outside = 0\n",
    "            for n in SG.nodes():\n",
    "                neighbors = G.neighbors(n)\n",
    "                for n1 in neighbors:\n",
    "                    if n1 not in SG:\n",
    "                        edges_outside += 1\n",
    "            edges_inside=SG.number_of_edges()\n",
    "            delta = edges_inside - edges_outside        \n",
    "            dict_weak[c]=delta    \n",
    "        kunci = max(dict_weak,key=dict_weak.get)\n",
    "        nilai=dictcom[kunci]\n",
    "        communities.pop(kunci)   # menghapus elemen komunitas\n",
    "        c_star = [*nilai, ]\n",
    "        for el in c_star:\n",
    "            communities[el] = frozenset({el})\n",
    "    return (communities)\n",
    "\n",
    "def pecah_high_conductance(communities):\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    dict_conductance={} \n",
    "    if (len(dictcom)>=1):\n",
    "        for c in dictcom:\n",
    "            SG = G.subgraph(communities[c]) \n",
    "            ms = len(SG.edges())\n",
    "            edges_outside = 0\n",
    "            for n in SG.nodes():\n",
    "                neighbors = G.neighbors(n)\n",
    "                for n1 in neighbors:\n",
    "                    if n1 not in SG:\n",
    "                        edges_outside += 1  \n",
    "            try:\n",
    "                scoreconductance = float(edges_outside) /((2 * ms) + edges_outside)\n",
    "            except:\n",
    "                scoreconductance = 0  \n",
    "            dict_conductance[c]=scoreconductance\n",
    "        #print(\"dict conductance\",dict_conductance)\n",
    "        kunci = max(dict_conductance,key=dict_conductance.get)\n",
    "        nilai=dictcom[kunci]\n",
    "        communities.pop(kunci)   # menghapus elemen komunitas\n",
    "        c_star = [*nilai, ]\n",
    "        for el in c_star:\n",
    "            communities[el] = frozenset({el})                \n",
    "    return (communities)\n",
    "\n",
    "def pecah_low_tpr(communities):\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    dict_tpr={} \n",
    "    if (len(dictcom)>=1):\n",
    "        for c in dictcom:\n",
    "            SG = G.subgraph(communities[c])             \n",
    "            dict_triangle = nx.triangles(SG)\n",
    "            node_triangle = [n for n in dict_triangle if dict_triangle[n] > 0]\n",
    "            scoretpr = float(len(node_triangle)) / len(SG)           \n",
    "            dict_tpr[c]=scoretpr \n",
    "        #print(\"dict tpr\", dict_tpr)\n",
    "        kunci = min(dict_tpr,key=dict_tpr.get)\n",
    "        nilai=dictcom[kunci]\n",
    "        communities.pop(kunci)   # menghapus elemen komunitas\n",
    "        c_star = [*nilai, ]\n",
    "        for el in c_star:\n",
    "            communities[el] = frozenset({el})             \n",
    "    return (communities)\n",
    "\n",
    "def pecah_low_edge_density(communities):\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    dict_density={} \n",
    "    if (len(dictcom)>=1):\n",
    "        for c in dictcom:\n",
    "            SG = G.subgraph(communities[c])\n",
    "            density = nx.density(SG)   \n",
    "            dict_density[c]=density\n",
    "        #print(\"dict_density\", dict_density)\n",
    "        kunci = min(dict_density,key=dict_density.get)\n",
    "        nilai=dictcom[kunci]\n",
    "        communities.pop(kunci)   # menghapus elemen komunitas\n",
    "        c_star = [*nilai, ]\n",
    "        for el in c_star:\n",
    "            communities[el] = frozenset({el})                         \n",
    "    return (communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2c3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lepas_random(communities):\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    if len(dictcom)>=1:\n",
    "        #print(\"alternatif  \",dictcom)\n",
    "        kunci, nilai = random.choice(list(dictcom.items()))\n",
    "        listnilai=[x for x in nilai ]\n",
    "        el_lepas = random.choice(listnilai)\n",
    "        #print(\"Yang dihapus \", kunci, listnilai, el_lepas )        \n",
    "        listnilai.remove(el_lepas)\n",
    "        communities.pop(kunci)\n",
    "        communities[el_lepas] = frozenset({el_lepas})\n",
    "        subgraphsisa =  G.subgraph(listnilai)\n",
    "        listconns = [list(c) for c in nx.connected_components(subgraphsisa)]\n",
    "        #print('list connected component',listconns)\n",
    "        for  listconn in listconns:\n",
    "            communities[max(listconn)]=frozenset(listconn)\n",
    "        #print(\"hasil akhir:\", communities)\n",
    "    return (communities)\n",
    "\n",
    "def lepas_weak_node(communities):\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    if len(dictcom)>=1:\n",
    "        for c in dictcom: \n",
    "            list_node_komunitas = [x for x in  communities[c]]\n",
    "            #print(\"listnodekomunitas: \", list_node_komunitas)\n",
    "            for node_komunitas in list_node_komunitas:\n",
    "                list_edge_node_komunitas=list(G.edges(node_komunitas))\n",
    "                in_comm = 0\n",
    "                out_comm= 0\n",
    "                for e in list_edge_node_komunitas:\n",
    "                    if e[1] in list_node_komunitas:\n",
    "                        in_comm += 1\n",
    "                    else:\n",
    "                        out_comm += 1\n",
    "                #print(c,node_komunitas,in_comm, out_comm)\n",
    "                if in_comm>=2 and out_comm>in_comm:\n",
    "                    elemen=list(communities[c])\n",
    "                    communities[c]=frozenset()\n",
    "                    #print(\"elemen komunitas yang akan dilepas\", elemen)\n",
    "                    for el in elemen:\n",
    "                        communities[el]=frozenset()\n",
    "                    sisa=[item for item in elemen if item != node_komunitas]\n",
    "                    communities[node_komunitas]=frozenset({node_komunitas})\n",
    "                    subgraphsisa =  G.subgraph(sisa)\n",
    "                    listconns = [list(c) for c in nx.connected_components(subgraphsisa)]\n",
    "                    for  listconn in listconns:\n",
    "                        communities[max(listconn)]=frozenset(listconn)\n",
    "                    break;                 \n",
    "    return (communities)\n",
    "\n",
    "def lepas_non_triad_node(communities):\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    if len(dictcom)>=1:\n",
    "        for c in dictcom: \n",
    "            if len(communities[c])>=4:\n",
    "                SG=G.subgraph(communities[c])\n",
    "                SGTriangle = nx.triangles(SG)\n",
    "                not_tpn = [n for n in SGTriangle if SGTriangle[n] == 0] \n",
    "                if len(not_tpn)>0:\n",
    "                    listkom=list(communities[c])\n",
    "                    communities[c]=frozenset()\n",
    "                    for el in not_tpn:\n",
    "                        communities[el]=frozenset({el})\n",
    "                    sisa=[item for item in listkom if item not in not_tpn]\n",
    "                    subgraphsisa =  G.subgraph(sisa)\n",
    "                    listconns = [list(c) for c in nx.connected_components(subgraphsisa)]\n",
    "                    for  listconn in listconns:\n",
    "                        communities[max(listconn)]=frozenset(listconn)\n",
    "                    break;\n",
    "    return (communities)\n",
    "\n",
    "def lepas_low_embeddedness_node(communities):\n",
    "    global G\n",
    "    #print(\"komunitas: \",communities)\n",
    "    dictcom={}\n",
    "    for x in communities:\n",
    "        if len(communities[x])>1:\n",
    "            dictcom[x]=communities[x]\n",
    "    if len(dictcom)>=1:\n",
    "        dictemb={}\n",
    "        for c in dictcom:     \n",
    "            listkom=list(communities[c])\n",
    "            SG=G.subgraph(communities[c])\n",
    "            for node in listkom:\n",
    "                dictemb[node]=SG.degree[node]/G.degree[node]\n",
    "        #print(dictemb)\n",
    "        if len(dictemb)>0:\n",
    "            dilepas = min(dictemb,key=dictemb.get) \n",
    "            #print(\"yang dilepas\",dilepas)\n",
    "            for key, value in communities.items():\n",
    "                if dilepas in value:\n",
    "                    nomor_komunitas=key\n",
    "            #print(\"nomor komunitas\",nomor_komunitas)             \n",
    " \n",
    "            listkom=list(communities[nomor_komunitas])\n",
    "            communities[nomor_komunitas]=frozenset({}) \n",
    "            communities[dilepas]=frozenset({dilepas})    \n",
    "\n",
    "            #print(\"listkom \", listkom)\n",
    "            sisa=[item for item in listkom if item != dilepas]\n",
    "            #print(\"sisa \", sisa)\n",
    "            subgraphsisa =  G.subgraph(sisa)\n",
    "            listconns = [list(c) for c in nx.connected_components(subgraphsisa)]\n",
    "            for  listconn in listconns:\n",
    "                communities[max(listconn)]=frozenset(listconn)                     \n",
    "    #print(communities)    \n",
    "    return (communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72bbfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_nodes_each(G,k,v):\n",
    "    #print(k,v)\n",
    "    edges = list(G.edges)\n",
    "    new_edges = []\n",
    "    for n1, n2 in edges:        \n",
    "        if n1 in v:\n",
    "            n1 = k\n",
    "        if n2 in v:\n",
    "            n2 = k\n",
    "        if n1 == n2:\n",
    "            continue\n",
    "        new_edges.append((n1,n2))\n",
    "        #print(\"n1 n2\",n1,n2)\n",
    "    H = nx.Graph()\n",
    "    H.add_edges_from(new_edges)\n",
    "    return H\n",
    "\n",
    "def collapse_nodes(G, initcom):\n",
    "    for  k,v in initcom.items():\n",
    "        if len(v)>1:\n",
    "            #print(k,list(v))        \n",
    "            G=collapse_nodes_each(G,k,list(v))\n",
    "    return G\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    #https://stackoverflow.com/questions/54610818/difference-between-two-list-of-unordered-tuples\n",
    "    if lst1 and lst2:\n",
    "        #lst3 = [value for value in lst1 if value in lst2]\n",
    "        #setlst3 = set.intersection(set(lst1), set(lst2))\n",
    "        #lst3=list(setlst3)\n",
    "        #lst3= np.intersect1d(lst1, lst2)\n",
    "        \n",
    "        lst3= set([tuple(sorted(elem))for elem in lst1]) & set([tuple(sorted(elem))for elem in lst2])\n",
    "        #print(lst1, lst2, lst3)\n",
    "    else:\n",
    "        lst3=[]\n",
    "    #print(lst1, lst2,lst3)\n",
    "    return lst3\n",
    "\n",
    "\n",
    "def alternative_intersection(lst1, lst2):\n",
    "    if not lst1 or not lst2:\n",
    "        return []\n",
    "\n",
    "    # Mengurutkan dan menyimpan elemen unik dari lst1 dalam dictionary\n",
    "    dict1 = {tuple(sorted(elem)): True for elem in lst1}\n",
    "\n",
    "    # Mencari irisan dengan lst2\n",
    "    intersection_set = set()\n",
    "    for elem in lst2:\n",
    "        sorted_elem = tuple(sorted(elem))\n",
    "        if dict1.get(sorted_elem, False):\n",
    "            intersection_set.add(sorted_elem)\n",
    "\n",
    "    return list(intersection_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053b9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yang iterasi greedy diambilkan dari greedy modularity yang telah ada sebelumnya\n",
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/\n",
    "# networkx.algorithms.community.modularity_max.greedy_modularity_communities.html\n",
    "def greedy_modularity_iteration(G, communities,weight=None, resolution=1):\n",
    "    global GG, H, dq_heap, dq_dict, numedges, berhenti, mulai\n",
    "    \n",
    "\n",
    "    if mulai:\n",
    "        GG = collapse_nodes(G, communities)\n",
    "        m = G.size(weight)\n",
    "        q0 = 1 / m\n",
    "        a = b = {node: deg * q0 for node, deg in G.degree(weight=weight)}\n",
    "        #print(\"nilai a\",a)\n",
    "        numedges=len(G.edges())\n",
    "        dq_dict = defaultdict(lambda: defaultdict(float))\n",
    "        for u, v, wt in GG.edges(data=weight, default=1):\n",
    "            if u == v:\n",
    "                continue\n",
    "            elci = G.edges(list(communities[u]))\n",
    "            elcj = G.edges(list(communities[v]))\n",
    "            join=intersection(elci,elcj)\n",
    "            if len(join)==0:\n",
    "                continue   \n",
    "            eij=len(join)/numedges    \n",
    "            ai = len(G.edges(communities[u]))/numedges\n",
    "            aj = len(G.edges(communities[v]))/numedges\n",
    "            dq= 2*(eij-ai*aj) \n",
    "            dq_dict[u][v] = dq\n",
    "            dq_dict[v][u] = dq\n",
    "            #print(\"u, v, dq\",u,v, dq)\n",
    "        #cetak_dq_dict(dq_dict)\n",
    "\n",
    "        dq_heap = {u: MappedQueue({(u, v): -dq for v, dq in dq_dict[u].items()}) for u in G}\n",
    "        #cdq_heap = copy.deepcopy(dq_heap)\n",
    "        #cetak_dq_heap(cdq_heap)\n",
    "\n",
    "        H = MappedQueue([dq_heap[n].heap[0] for n in G if len(dq_heap[n]) > 0])\n",
    "        berhenti=False\n",
    "\n",
    "        #HH =copy.deepcopy(H)  \n",
    "        #cetak_mapped_queue(HH)\n",
    "        #print(\"mulai\")\n",
    "    else:\n",
    "        berhenti=True\n",
    "        if len(H) > 1:\n",
    "            try:\n",
    "                negdq, u, v = H.pop()\n",
    "            except IndexError:\n",
    "                return(communities, True)\n",
    "            dq = -negdq\n",
    "            #print(\"u v dq\",u, v, dq)\n",
    "            if dq>0:\n",
    "                berhenti=False\n",
    "                # Remove best merge from row u heap\n",
    "                dq_heap[u].pop()\n",
    "                # Push new row max onto H\n",
    "                if len(dq_heap[u]) > 0:\n",
    "                    H.push(dq_heap[u].heap[0])\n",
    "                # If this element was also at the root of row v, we need to remove the\n",
    "                # duplicate entry from H\n",
    "                if dq_heap[v].heap[0] == (v, u):\n",
    "                    H.remove((v, u))\n",
    "                    # Remove best merge from row v heap\n",
    "                    dq_heap[v].remove((v, u))\n",
    "                    # Push new row max onto H\n",
    "                    if len(dq_heap[v]) > 0:\n",
    "                        H.push(dq_heap[v].heap[0])\n",
    "                else:\n",
    "                    # Duplicate wasn't in H, just remove from row v heap\n",
    "                    dq_heap[v].remove((v, u))\n",
    "                #cdq_heap = copy.deepcopy(dq_heap)\n",
    "                #cetak_dq_heap(cdq_heap)       \n",
    "\n",
    "                #print(\"u,v: \", u,v)\n",
    "                #print(\"communities u, v SEBELUM : \", communities[u] , communities[v])            \n",
    "                communities[v] = frozenset(communities[u] | communities[v])        \n",
    "                del communities[u]\n",
    "\n",
    "                #print(\"yang digabung \", max(list(communities[v])), list(communities[v]))            \n",
    "                #print(\"communities\", communities)\n",
    "                GG=collapse_nodes_each(GG,max(list(communities[v])),list(communities[v]))\n",
    "\n",
    "                # Get neighbor communities connected to the merged communities\n",
    "                u_nbrs = set(dq_dict[u])\n",
    "                v_nbrs = set(dq_dict[v])\n",
    "                all_nbrs = (u_nbrs | v_nbrs) - {u, v}\n",
    "                both_nbrs = u_nbrs & v_nbrs\n",
    "                # Update dq for merge of u into v\n",
    "                for w in all_nbrs:\n",
    "                    # Calculate new dq value\n",
    "                    #if w in both_nbrs:\n",
    "                    #    dq_vw = dq_dict[v][w] + dq_dict[u][w]\n",
    "                    #elif w in v_nbrs:\n",
    "                    #    dq_vw = dq_dict[v][w] - resolution * (a[u] * b[w] + a[w] * b[u])\n",
    "                    #else:  # w in u_nbrs\n",
    "                    #    dq_vw = dq_dict[u][w] - resolution * (a[v] * b[w] + a[w] * b[v])\n",
    "                    # Update rows v and w\n",
    "                    for row, col in [(v, w), (w, v)]:\n",
    "                        dq_heap_row = dq_heap[row]\n",
    "                        # Update dict for v,w only (u is removed below)\n",
    "                        elci = G.edges(list(communities[row]))\n",
    "                        elcj = G.edges(list(communities[col]))\n",
    "                        join=intersection(elci,elcj)\n",
    "                        if len(join)==0:\n",
    "                            continue   \n",
    "                        eij=len(join)/numedges    \n",
    "                        ai = len(G.edges(communities[row]))/numedges\n",
    "                        aj = len(G.edges(communities[col]))/numedges\n",
    "                        dq_vw= 2*(eij-ai*aj) \n",
    "                        #dq_dict[u][v] = dq\n",
    "                        #dq_dict[v][u] = dq\n",
    "\n",
    "                        dq_dict[row][col] = dq_vw\n",
    "                        # Save old max of per-row heap\n",
    "                        if len(dq_heap_row) > 0:\n",
    "                            d_oldmax = dq_heap_row.heap[0]\n",
    "                        else:\n",
    "                            d_oldmax = None\n",
    "                        # Add/update heaps\n",
    "                        d = (row, col)\n",
    "                        d_negdq = -dq_vw\n",
    "                        # Save old value for finding heap index\n",
    "                        if w in v_nbrs:\n",
    "                            # Update existing element in per-row heap\n",
    "                            dq_heap_row.update(d, d, priority=d_negdq)\n",
    "                        else:\n",
    "                            # We're creating a new nonzero element, add to heap\n",
    "                            dq_heap_row.push(d, priority=d_negdq)\n",
    "                        # Update heap of row maxes if necessary\n",
    "                        if d_oldmax is None:\n",
    "                            # No entries previously in this row, push new max\n",
    "                            H.push(d, priority=d_negdq)\n",
    "                        else:\n",
    "                            # We've updated an entry in this row, has the max changed?\n",
    "                            row_max = dq_heap_row.heap[0]\n",
    "                            if d_oldmax != row_max or d_oldmax.priority != row_max.priority:\n",
    "                                H.update(d_oldmax, row_max)\n",
    "\n",
    "                # Remove row/col u from dq_dict matrix\n",
    "                for w in dq_dict[u]:\n",
    "                    # Remove from dict\n",
    "                    dq_old = dq_dict[w][u]\n",
    "                    del dq_dict[w][u]\n",
    "                    # Remove from heaps if we haven't already\n",
    "                    if w != v:\n",
    "                        # Remove both row and column\n",
    "                        for row, col in [(w, u), (u, w)]:\n",
    "                            dq_heap_row = dq_heap[row]\n",
    "                            # Check if replaced dq is row max\n",
    "                            d_old = (row, col)\n",
    "                            if dq_heap_row.heap[0] == d_old:\n",
    "                                # Update per-row heap and heap of row maxes\n",
    "                                dq_heap_row.remove(d_old)\n",
    "                                H.remove(d_old)\n",
    "                                # Update row max\n",
    "                                if len(dq_heap_row) > 0:\n",
    "                                    H.push(dq_heap_row.heap[0])\n",
    "                            else:\n",
    "                                # Only update per-row heap\n",
    "                                dq_heap_row.remove(d_old)\n",
    "\n",
    "                del dq_dict[u]\n",
    "                # Mark row u as deleted, but keep placeholder\n",
    "                dq_heap[u] = MappedQueue()\n",
    "\n",
    "                #cetak_dq_dict(dq_dict)\n",
    "                #cdq_heap = copy.deepcopy(dq_heap)\n",
    "                #cetak_dq_heap(cdq_heap)\n",
    "            else:\n",
    "                berhenti=True\n",
    "                #print(\"berhenti\")\n",
    "\n",
    "    #print(communities)\n",
    "    #print(\"==== SELESAI ITERASI ==================\")\n",
    "        \n",
    "    return communities, berhenti\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3be1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_modularity(G, iterasi=10, modepecah=0, modelepas=0):\n",
    "    global mulai\n",
    "    communities = {n: frozenset([n]) for n in G}\n",
    "    #print(communities)\n",
    "    GG=G\n",
    "    mulai=True\n",
    "    #print(communities)\n",
    "    n=len(G.nodes())*iterasi\n",
    "    komunitasterbaik=communities;\n",
    "    modularitasterbaik = hitungmodularitas(G,komunitasterbaik)\n",
    "    #print(modularitasterbaik, reformat2(G,komunitasterbaik))\n",
    "\n",
    "    #pil = [0,0,0,0,0,0,0,1,0,0,0]\n",
    "    berhenti=False\n",
    "    for i in range(n):\n",
    "        if ((i % 100)==0):\n",
    "            print(\".\",end=\"\")\n",
    "        #print(i, mulai, communities) \n",
    "        if i<len(G.nodes()):\n",
    "            pilihan=0\n",
    "        else:\n",
    "            pilihan=random.choices([0,1,2], [0.9,0.05, 0.05])[0]\n",
    "        #pilihan=random.choices([0,1], [0.95,0.05])[0]\n",
    "        #pilihan = pil[i]\n",
    "\n",
    "        if pilihan == 0:\n",
    "            communities,  berhenti=greedy_modularity_iteration(G, communities)\n",
    "            #print(i,communities)\n",
    "            mulai=False\n",
    "        if berhenti:\n",
    "            komunitasterbaik, modularitasterbaik= updatekomunitasterbaik(G,communities,komunitasterbaik, modularitasterbaik);\n",
    "            #print(\"update terbaik\",i,modularitasterbaik)\n",
    "        if (pilihan ==1 or berhenti):\n",
    "            if modepecah==0: \n",
    "                communities = pecah_random(communities)\n",
    "            elif modepecah==1:\n",
    "                communities = pecah_weak(communities)                \n",
    "            elif modepecah==2:\n",
    "                communities = pecah_high_conductance(communities)                \n",
    "            elif modepecah==3:\n",
    "                communities = pecah_low_tpr(communities)                \n",
    "            else: #modepecah==4\n",
    "                communities = pecah_low_edge_density(communities)                                \n",
    "            mulai=True\n",
    "        if (pilihan ==2 or berhenti):\n",
    "            if modelepas==0:\n",
    "                communities = lepas_random(communities)\n",
    "            elif modelepas==1:\n",
    "                communities = lepas_weak_node(communities)\n",
    "            elif modelepas==2:\n",
    "                communities = lepas_non_triad_node(communities)\n",
    "            else: # modelepas==3:\n",
    "                communities = lepas_low_embeddedness_node(communities)\n",
    "            mulai=True            \n",
    "    #print(komunitasterbaik)\n",
    "    return komunitasterbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef2e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......Karate 34 0.41880341880341876 pecah_random lepas_random 0.5794482231140137\n",
      ".......Karate 34 0.41880341880341876 pecah_random lepas_weak_node 0.6013906002044678\n",
      ".......Karate 34 0.41978961209730437 pecah_random lepas_non_triad_node 0.5904490947723389\n",
      ".......Karate 34 0.41559829059829057 pecah_random lepas_low_embeddedness_node 0.5993680953979492\n",
      ".......Karate 34 0.41978961209730437 pecah_weak lepas_random 0.6761643886566162\n",
      ".......Karate 34 0.41880341880341876 pecah_weak lepas_weak_node 0.640315055847168\n",
      ".......Karate 34 0.41978961209730437 pecah_weak lepas_non_triad_node 0.6293158531188965\n",
      ".......Karate 34 0.41880341880341876 pecah_weak lepas_low_embeddedness_node 0.6272933483123779\n",
      ".......Karate 34 0.41978961209730437 pecah_high_conductance lepas_random 0.5116274356842041\n",
      ".......Karate 34 0.388560157790927 pecah_high_conductance lepas_weak_node 0.5435488224029541\n",
      ".......Karate 34 0.3921761998685076 pecah_high_conductance lepas_non_triad_node 0.5475351810455322\n",
      ".......Karate 34 0.394888231426693 pecah_high_conductance lepas_low_embeddedness_node 0.5295510292053223\n",
      ".......Karate 34 0.41880341880341876 pecah_low_tpr lepas_random 0.5390007495880127\n",
      ".......Karate 34 0.388560157790927 pecah_low_tpr lepas_weak_node 0.5707898139953613\n",
      ".......Karate 34 0.39217619986850755 pecah_low_tpr lepas_non_triad_node 0.6023879051208496\n",
      ".......Karate 34 0.394888231426693 pecah_low_tpr lepas_low_embeddedness_node 0.5894229412078857\n",
      ".......Karate 34 0.3895463510848126 pecah_low_edge_density lepas_random 0.6592636108398438\n",
      ".......Karate 34 0.41880341880341876 pecah_low_edge_density lepas_weak_node 0.6811470985412598\n",
      ".......Karate 34 0.388560157790927 pecah_low_edge_density lepas_non_triad_node 0.6502888202667236\n",
      ".......Karate 34 0.41880341880341876 pecah_low_edge_density lepas_low_embeddedness_node 0.6741712093353271\n",
      ".............Dolphins 62 0.5258692298564139 pecah_random lepas_random 1.5887489318847656\n",
      ".............Dolphins 62 0.5258692298564139 pecah_random lepas_weak_node 1.787250280380249\n",
      ".............Dolphins 62 0.5258692298564139 pecah_random lepas_non_triad_node 1.7667460441589355\n",
      ".............Dolphins 62 0.5258692298564139 pecah_random lepas_low_embeddedness_node 1.6306376457214355\n",
      ".............Dolphins 62 0.5258692298564139 pecah_weak lepas_random 1.8290770053863525\n",
      ".............Dolphins 62 0.5258692298564139 pecah_weak lepas_weak_node 1.9687316417694092\n",
      ".............Dolphins 62 0.5258692298564139 pecah_weak lepas_non_triad_node 1.7712595462799072\n",
      ".............Dolphins 62 0.5258692298564139 pecah_weak lepas_low_embeddedness_node 1.9886505603790283\n",
      ".............Dolphins 62 0.5258692298564139 pecah_high_conductance lepas_random 1.6191704273223877\n",
      ".............Dolphins 62 0.5258692298564138 pecah_high_conductance lepas_weak_node 1.8031749725341797\n",
      ".............Dolphins 62 0.512855504133539 pecah_high_conductance lepas_non_triad_node 1.7981877326965332\n",
      ".............Dolphins 62 0.5258692298564138 pecah_high_conductance lepas_low_embeddedness_node 1.6276726722717285\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_tpr lepas_random 1.9228267669677734\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_tpr lepas_weak_node 2.0176289081573486\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_tpr lepas_non_triad_node 1.9537444114685059\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_tpr lepas_low_embeddedness_node 1.9668388366699219\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_edge_density lepas_random 1.950796365737915\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_edge_density lepas_weak_node 1.9009122848510742\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_edge_density lepas_non_triad_node 2.1239402294158936\n",
      ".............Dolphins 62 0.5258692298564139 pecah_low_edge_density lepas_low_embeddedness_node 1.904902458190918\n",
      "................lesmis 77 0.5561333622667245 pecah_random lepas_random 3.3031651973724365\n",
      "................lesmis 77 0.5561333622667245 pecah_random lepas_weak_node 3.604186773300171\n",
      "................lesmis 77 0.5561333622667245 pecah_random lepas_non_triad_node 3.8177831172943115\n",
      "................lesmis 77 0.5561333622667245 pecah_random lepas_low_embeddedness_node 3.3041582107543945\n",
      "................lesmis 77 0.5561333622667245 pecah_weak lepas_random 3.6833386421203613\n",
      "................lesmis 77 0.5561333622667245 pecah_weak lepas_weak_node 4.284287929534912\n",
      "................lesmis 77 0.5561333622667245 pecah_weak lepas_non_triad_node 4.1626362800598145\n",
      "................lesmis 77 0.5561333622667245 pecah_weak lepas_low_embeddedness_node 3.3560171127319336\n",
      "................lesmis 77 0.5561333622667245 pecah_high_conductance lepas_random 2.8762998580932617\n",
      "................lesmis 77 0.5561333622667245 pecah_high_conductance lepas_weak_node 3.3981807231903076\n",
      "................lesmis 77 0.5561333622667245 pecah_high_conductance lepas_non_triad_node 3.6527442932128906\n",
      "................lesmis 77 0.5561333622667245 pecah_high_conductance lepas_low_embeddedness_node 3.25030255317688\n",
      "................lesmis 77 0.5561333622667245 pecah_low_tpr lepas_random 3.660743236541748\n",
      "................lesmis 77 0.5561333622667245 pecah_low_tpr lepas_weak_node 3.49664306640625\n",
      "................lesmis 77 0.5561333622667245 pecah_low_tpr lepas_non_triad_node 3.491685152053833\n",
      "................lesmis 77 0.5561333622667245 pecah_low_tpr lepas_low_embeddedness_node 3.5734376907348633\n",
      "................lesmis 77 0.5561333622667245 pecah_low_edge_density lepas_random 3.966433525085449\n",
      "................lesmis 77 0.5561333622667245 pecah_low_edge_density lepas_weak_node 3.9298219680786133\n",
      "................lesmis 77 0.5561333622667245 pecah_low_edge_density lepas_non_triad_node 3.8541979789733887\n",
      "................lesmis 77 0.5561333622667245 pecah_low_edge_density lepas_low_embeddedness_node 3.700162172317505\n",
      ".....................polbooks 105 0.49541600464826907 pecah_random lepas_random 14.209320306777954\n",
      ".....................polbooks 105 0.5046251304754706 pecah_random lepas_weak_node 12.93068814277649\n",
      ".....................polbooks 105 0.5269383641589667 pecah_random lepas_non_triad_node 14.6662437915802\n",
      ".....................polbooks 105 0.49927242249885595 pecah_random lepas_low_embeddedness_node 13.835985898971558\n",
      ".....................polbooks 105 0.49541600464826907 pecah_weak lepas_random 16.278108596801758\n",
      ".....................polbooks 105 0.49541600464826907 pecah_weak lepas_weak_node 16.397608041763306\n",
      ".....................polbooks 105 0.49541600464826907 pecah_weak lepas_non_triad_node 16.60279130935669\n",
      ".....................polbooks 105 0.49541600464826907 pecah_weak lepas_low_embeddedness_node 16.426936626434326\n",
      ".....................polbooks 105 0.502660928316905 pecah_high_conductance lepas_random 9.320641040802002\n",
      ".....................polbooks 105 0.49927242249885595 pecah_high_conductance lepas_weak_node 9.050343751907349\n",
      ".....................polbooks 105 0.49927242249885595 pecah_high_conductance lepas_non_triad_node 9.723523616790771\n",
      ".....................polbooks 105 0.502660928316905 pecah_high_conductance lepas_low_embeddedness_node 9.397554159164429\n",
      ".....................polbooks 105 0.49927242249885595 pecah_low_tpr lepas_random 13.278959512710571\n",
      ".....................polbooks 105 0.5046251304754706 pecah_low_tpr lepas_weak_node 13.573995590209961\n",
      ".....................polbooks 105 0.5046251304754706 pecah_low_tpr lepas_non_triad_node 13.74425482749939\n",
      ".....................polbooks 105 0.5046251304754706 pecah_low_tpr lepas_low_embeddedness_node 14.164456844329834\n",
      ".....................polbooks 105 0.49541600464826907 pecah_low_edge_density lepas_random 15.815211534500122\n",
      ".....................polbooks 105 0.49541600464826907 pecah_low_edge_density lepas_weak_node 15.382512331008911\n",
      ".....................polbooks 105 0.5046251304754706 pecah_low_edge_density lepas_non_triad_node 16.48312997817993\n",
      ".....................polbooks 105 0.49541600464826907 pecah_low_edge_density lepas_low_embeddedness_node 15.854572296142578\n",
      ".......................adjnoun 112 0.302557785467128 pecah_random lepas_random 9.40111494064331\n",
      ".......................adjnoun 112 0.288398615916955 pecah_random lepas_weak_node 12.260866641998291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................adjnoun 112 0.29841937716262973 pecah_random lepas_non_triad_node 11.2329421043396\n",
      ".......................adjnoun 112 0.29302975778546714 pecah_random lepas_low_embeddedness_node 9.817140579223633\n",
      ".......................adjnoun 112 0.3025217993079585 pecah_weak lepas_random 8.585837841033936\n",
      ".......................adjnoun 112 0.29167058823529407 pecah_weak lepas_weak_node 11.214717864990234\n",
      ".......................adjnoun 112 0.2955100346020761 pecah_weak lepas_non_triad_node 9.461357355117798\n",
      ".......................adjnoun 112 0.2846782006920415 pecah_weak lepas_low_embeddedness_node 11.724502801895142\n",
      ".......................adjnoun 112 0.2913771626297578 pecah_high_conductance lepas_random 11.018991947174072\n",
      ".......................adjnoun 112 0.2903861591695502 pecah_high_conductance lepas_weak_node 12.130197286605835\n",
      ".......................adjnoun 112 0.299042214532872 pecah_high_conductance lepas_non_triad_node 9.98858380317688\n",
      ".......................adjnoun 112 0.2830145328719723 pecah_high_conductance lepas_low_embeddedness_node 11.970108270645142\n",
      ".......................adjnoun 112 0.29821176470588234 pecah_low_tpr lepas_random 9.081151723861694\n",
      ".......................adjnoun 112 0.29604705882352944 pecah_low_tpr lepas_weak_node 12.306594133377075\n",
      ".......................adjnoun 112 0.2897522491349481 pecah_low_tpr lepas_non_triad_node 9.198357582092285\n",
      ".......................adjnoun 112 0.2919501730103806 pecah_low_tpr lepas_low_embeddedness_node 9.570086479187012\n",
      ".......................adjnoun 112 0.29513633217993085 pecah_low_edge_density lepas_random 10.551874160766602\n",
      ".......................adjnoun 112 0.27467128027681664 pecah_low_edge_density lepas_weak_node 13.349278211593628\n",
      ".......................adjnoun 112 0.2880941176470588 pecah_low_edge_density lepas_non_triad_node 11.623866319656372\n",
      ".......................adjnoun 112 0.288484429065744 pecah_low_edge_density lepas_low_embeddedness_node 10.319000005722046\n",
      ".......................football 115 0.577618164350971 pecah_random lepas_random 20.083576917648315\n",
      ".......................football 115 0.6006416175895297 pecah_random lepas_weak_node 18.890357971191406\n",
      ".......................football 115 0.5993961715841382 pecah_random lepas_non_triad_node 16.05381441116333\n",
      ".......................football 115 0.5936466286468549 pecah_random lepas_low_embeddedness_node 15.696129322052002\n",
      ".......................football 115 0.579801686674526 pecah_weak lepas_random 20.08849263191223\n",
      ".......................football 115 0.5826345440949093 pecah_weak lepas_weak_node 21.19229221343994\n",
      ".......................football 115 0.5825799893019381 pecah_weak lepas_non_triad_node 18.832889080047607\n",
      ".......................football 115 0.5978792822185971 pecah_weak lepas_low_embeddedness_node 20.063483476638794\n",
      ".......................football 115 0.5842964693734715 pecah_high_conductance lepas_random 11.179917812347412\n",
      ".......................football 115 0.5880620806931919 pecah_high_conductance lepas_weak_node 12.81552767753601\n",
      ".......................football 115 0.5842964693734715 pecah_high_conductance lepas_non_triad_node 12.488147497177124\n",
      ".......................football 115 0.5868166346878002 pecah_high_conductance lepas_low_embeddedness_node 12.361764907836914\n",
      ".......................football 115 0.5906793801511034 pecah_low_tpr lepas_random 18.81843876838684\n",
      ".......................football 115 0.6006416175895296 pecah_low_tpr lepas_weak_node 15.748484134674072\n",
      ".......................football 115 0.5801489745029526 pecah_low_tpr lepas_non_triad_node 18.33481478691101\n",
      ".......................football 115 0.6031617829038585 pecah_low_tpr lepas_low_embeddedness_node 16.620880603790283\n",
      ".......................football 115 0.5738512224265441 pecah_low_edge_density lepas_random 18.954829454421997\n",
      ".......................football 115 0.5731260428614388 pecah_low_edge_density lepas_weak_node 22.070291996002197\n",
      ".......................football 115 0.5993349637676338 pecah_low_edge_density lepas_non_triad_node 20.033634901046753\n",
      ".......................football 115 0.5731260428614388 pecah_low_edge_density lepas_low_embeddedness_node 21.59274959564209\n"
     ]
    }
   ],
   "source": [
    "G=nx.Graph()\n",
    "#G.add_edges_from([(0,1),(1,2),(2,0),(2,3),(3,4),(4,5),(5,3)])\n",
    "\n",
    "G.add_edges_from ([(0, 1), (0, 2), (0, 3), (1, 3), (1, 2), (2, 6), (2, 3), (4, 5), (4, 6), (5, 6)])\n",
    "\n",
    "datasets=[\"Karate\",\"Dolphins\", \"lesmis\",\"polbooks\" ,\"adjnoun\",\"football\"] \n",
    "          \n",
    "\n",
    "listmodepecah = [\"pecah_random\", \"pecah_weak\",\"pecah_high_conductance\", \"pecah_low_tpr\", \"pecah_low_edge_density\"]\n",
    "listmodelepas=[\"lepas_random\",\"lepas_weak_node\", \"lepas_non_triad_node\", \"lepas_low_embeddedness_node\"]\n",
    "dfcom = pd.DataFrame(columns = [ 'dataset','simpul','iterasi','modepecah','modelepas','modularity','komunitas', 'n_komunitas','time'])\n",
    "#dataset=datasets[0]\n",
    "iterasi=20\n",
    "for dataset in datasets:\n",
    "    G = nx.read_gml(dataset+\".gml\", label = 'id')\n",
    "    #pos = nx.spring_layout(G)\n",
    "    #nx.draw(G, with_labels=True, node_size=500)\n",
    "    for modepecah in range(5):\n",
    "        for modelepas in range(4):\n",
    "            try:\n",
    "                awal = time.time()\n",
    "                komunitasterbaik=greedy_modularity(G,iterasi,modepecah,modelepas)\n",
    "                akhir= time.time()\n",
    "                bestcoms= reformat2(G,komunitasterbaik)\n",
    "                bestmodularitas = nx_comm.modularity(G,bestcoms)\n",
    "                waktu= akhir-awal\n",
    "                dftemp = {'dataset':dataset, \n",
    "                  'simpul':len(G.nodes()),\n",
    "                  'iterasi':iterasi,  \n",
    "                  'modepecah':listmodepecah[modepecah],\n",
    "                  'modelepas':listmodelepas[modelepas],\n",
    "                  'modularity':bestmodularitas,\n",
    "                  'komunitas':bestcoms,\n",
    "                  'n_komunitas':len(bestcoms),\n",
    "                  'time':waktu}\n",
    "                dfcom = dfcom.append(dftemp,ignore_index=True) \n",
    "                print(dataset, len(G.nodes()), bestmodularitas,listmodepecah[modepecah], listmodelepas[modelepas],  waktu)\n",
    "            except:\n",
    "                print(dataset, len(G.nodes()), \"-\", listmodepecah[modepecah], listmodelepas[modelepas], \"-\")\n",
    "    #print(\"modularitas %.4f\" % bestmodularitas)\n",
    "    #print(\"waktu %.4f detik\" % selisih )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2edbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>simpul</th>\n",
       "      <th>iterasi</th>\n",
       "      <th>modepecah</th>\n",
       "      <th>modelepas</th>\n",
       "      <th>modularity</th>\n",
       "      <th>komunitas</th>\n",
       "      <th>n_komunitas</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karate</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_random</td>\n",
       "      <td>lepas_random</td>\n",
       "      <td>0.418803</td>\n",
       "      <td>[[32, 24, 25, 26, 28, 29], [1, 2, 3, 4, 8, 10,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.579448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karate</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_random</td>\n",
       "      <td>lepas_weak_node</td>\n",
       "      <td>0.418803</td>\n",
       "      <td>[[5, 6, 7, 11, 17], [1, 2, 3, 4, 8, 10, 12, 13...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.601391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karate</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_random</td>\n",
       "      <td>lepas_non_triad_node</td>\n",
       "      <td>0.419790</td>\n",
       "      <td>[[1, 2, 3, 4, 8, 12, 13, 14, 18, 20, 22], [32,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.590449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karate</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_random</td>\n",
       "      <td>lepas_low_embeddedness_node</td>\n",
       "      <td>0.415598</td>\n",
       "      <td>[[32, 25, 26, 29], [1, 2, 3, 4, 8, 10, 12, 13,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.599368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karate</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_weak</td>\n",
       "      <td>lepas_random</td>\n",
       "      <td>0.419790</td>\n",
       "      <td>[[5, 6, 7, 11, 17], [1, 2, 3, 4, 8, 12, 13, 14...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.676164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>football</td>\n",
       "      <td>115</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_low_tpr</td>\n",
       "      <td>lepas_low_embeddedness_node</td>\n",
       "      <td>0.603162</td>\n",
       "      <td>[[34, 99, 36, 38, 71, 42, 43, 12, 14, 18, 85, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>16.620881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>football</td>\n",
       "      <td>115</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_low_edge_density</td>\n",
       "      <td>lepas_random</td>\n",
       "      <td>0.573851</td>\n",
       "      <td>[[73, 110, 46, 49, 114, 83, 53, 88], [64, 32, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>18.954829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>football</td>\n",
       "      <td>115</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_low_edge_density</td>\n",
       "      <td>lepas_weak_node</td>\n",
       "      <td>0.573126</td>\n",
       "      <td>[[34, 99, 38, 71, 43, 12, 14, 18, 85, 54, 26, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>22.070292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>football</td>\n",
       "      <td>115</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_low_edge_density</td>\n",
       "      <td>lepas_non_triad_node</td>\n",
       "      <td>0.599335</td>\n",
       "      <td>[[64, 32, 2, 100, 6, 39, 106, 13, 47, 15, 60],...</td>\n",
       "      <td>7</td>\n",
       "      <td>20.033635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>football</td>\n",
       "      <td>115</td>\n",
       "      <td>20</td>\n",
       "      <td>pecah_low_edge_density</td>\n",
       "      <td>lepas_low_embeddedness_node</td>\n",
       "      <td>0.573126</td>\n",
       "      <td>[[34, 99, 38, 71, 43, 12, 14, 18, 85, 54, 26, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>21.592750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset simpul iterasi               modepecah  \\\n",
       "0      Karate     34      20            pecah_random   \n",
       "1      Karate     34      20            pecah_random   \n",
       "2      Karate     34      20            pecah_random   \n",
       "3      Karate     34      20            pecah_random   \n",
       "4      Karate     34      20              pecah_weak   \n",
       "..        ...    ...     ...                     ...   \n",
       "115  football    115      20           pecah_low_tpr   \n",
       "116  football    115      20  pecah_low_edge_density   \n",
       "117  football    115      20  pecah_low_edge_density   \n",
       "118  football    115      20  pecah_low_edge_density   \n",
       "119  football    115      20  pecah_low_edge_density   \n",
       "\n",
       "                       modelepas  modularity  \\\n",
       "0                   lepas_random    0.418803   \n",
       "1                lepas_weak_node    0.418803   \n",
       "2           lepas_non_triad_node    0.419790   \n",
       "3    lepas_low_embeddedness_node    0.415598   \n",
       "4                   lepas_random    0.419790   \n",
       "..                           ...         ...   \n",
       "115  lepas_low_embeddedness_node    0.603162   \n",
       "116                 lepas_random    0.573851   \n",
       "117              lepas_weak_node    0.573126   \n",
       "118         lepas_non_triad_node    0.599335   \n",
       "119  lepas_low_embeddedness_node    0.573126   \n",
       "\n",
       "                                             komunitas n_komunitas       time  \n",
       "0    [[32, 24, 25, 26, 28, 29], [1, 2, 3, 4, 8, 10,...           4   0.579448  \n",
       "1    [[5, 6, 7, 11, 17], [1, 2, 3, 4, 8, 10, 12, 13...           4   0.601391  \n",
       "2    [[1, 2, 3, 4, 8, 12, 13, 14, 18, 20, 22], [32,...           4   0.590449  \n",
       "3    [[32, 25, 26, 29], [1, 2, 3, 4, 8, 10, 12, 13,...           4   0.599368  \n",
       "4    [[5, 6, 7, 11, 17], [1, 2, 3, 4, 8, 12, 13, 14...           4   0.676164  \n",
       "..                                                 ...         ...        ...  \n",
       "115  [[34, 99, 36, 38, 71, 42, 43, 12, 14, 18, 85, ...           8  16.620881  \n",
       "116  [[73, 110, 46, 49, 114, 83, 53, 88], [64, 32, ...           8  18.954829  \n",
       "117  [[34, 99, 38, 71, 43, 12, 14, 18, 85, 54, 26, ...           6  22.070292  \n",
       "118  [[64, 32, 2, 100, 6, 39, 106, 13, 47, 15, 60],...           7  20.033635  \n",
       "119  [[34, 99, 38, 71, 43, 12, 14, 18, 85, 54, 26, ...           6  21.592750  \n",
       "\n",
       "[120 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b862234",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcom.to_excel(\"hasil Databases.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3be5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
